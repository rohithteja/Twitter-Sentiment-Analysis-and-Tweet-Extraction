{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8. RoBERTa.ipynb","provenance":[{"file_id":"1dLIJOZ9Ar0G88j2Sreqg5nokTNm0UAyM","timestamp":1608768028418}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"aa165c4c8d4a4bdba30d669f59906d15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ec0c4d438e34833979e9caa837ba5a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14fd1204a16d4c3692e57e2852041c2b","IPY_MODEL_6117124ef56747cb9660a3b0a1320814"]}},"6ec0c4d438e34833979e9caa837ba5a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14fd1204a16d4c3692e57e2852041c2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_18ac3a6a121c4a18910759f5c69e22f1","_dom_classes":[],"description":"Epoch: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_36db65bfa8214685b95ea2ea46b81bda"}},"6117124ef56747cb9660a3b0a1320814":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_244e5d1e610e4e7180f83fa6e3ab8ab7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [12:23&lt;00:00, 248.00s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e803ea8467d848888de63596f4ee1920"}},"18ac3a6a121c4a18910759f5c69e22f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"36db65bfa8214685b95ea2ea46b81bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"244e5d1e610e4e7180f83fa6e3ab8ab7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e803ea8467d848888de63596f4ee1920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dc452a3c7a0842309e44f5a32c1b82bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e8412f4d3b8e46ab81d4f301157f00be","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e8a92849a76642a7ab2b186ae0df4ae7","IPY_MODEL_eaa7ef95bed7416aa97237bcff09b7af"]}},"e8412f4d3b8e46ab81d4f301157f00be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8a92849a76642a7ab2b186ae0df4ae7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_853d9a7b580a474aafa0941123ff863b","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2405,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2405,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f78a0941ba24435b1ad3f9de377fcd7"}},"eaa7ef95bed7416aa97237bcff09b7af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3a2ae730cb3d470ab40b96c8e4e67058","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2405/2405 [12:23&lt;00:00,  3.23it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ead4e7718c7a497bb0bc54fe8e19ae35"}},"853d9a7b580a474aafa0941123ff863b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4f78a0941ba24435b1ad3f9de377fcd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a2ae730cb3d470ab40b96c8e4e67058":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ead4e7718c7a497bb0bc54fe8e19ae35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ca3c971fe77d454eaf3179146487dc44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_82b8beb2e5284052846d9e1a554b65e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cd664e45c6b24bc791ab4c063dd97b01","IPY_MODEL_866d76086148468f8409464495f5b65e"]}},"82b8beb2e5284052846d9e1a554b65e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd664e45c6b24bc791ab4c063dd97b01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a125e2c861bf40f88ec5448bb0ac14a4","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2405,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2405,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa163f956a7a48669f70ebbc50912fa9"}},"866d76086148468f8409464495f5b65e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_aff54d05e66d4eddb83fec133c002263","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2405/2405 [09:09&lt;00:00,  4.38it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_305cb5e80a6943e6a714908a088c0398"}},"a125e2c861bf40f88ec5448bb0ac14a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aa163f956a7a48669f70ebbc50912fa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aff54d05e66d4eddb83fec133c002263":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"305cb5e80a6943e6a714908a088c0398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c980297feeca4330a7ec8cd7b3611d63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_738d1f6643bb4d0784fc279254b24134","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_43dd7167468747d9aac84ae9a003e42f","IPY_MODEL_91a9349ed14b49cea0bd1d2762dfa7cf"]}},"738d1f6643bb4d0784fc279254b24134":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43dd7167468747d9aac84ae9a003e42f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3f1bbd86cedd44d79d5b9bbb1f502bd4","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2405,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2405,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_142219a840f3408d9b951aa884fa4362"}},"91a9349ed14b49cea0bd1d2762dfa7cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b75ec03a81894ce6a13e232ad16222ab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2405/2405 [05:54&lt;00:00,  6.79it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_638ece11c7014635a228491add1be51d"}},"3f1bbd86cedd44d79d5b9bbb1f502bd4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"142219a840f3408d9b951aa884fa4362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b75ec03a81894ce6a13e232ad16222ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"638ece11c7014635a228491add1be51d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfcc3e8bb29142aaaf0cf2a9d4ecce92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1acce1360fef474aa86b9abd11d6faab","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1cd501aa81f345d185b19a3f741e50d4","IPY_MODEL_500f8f5204db452f9ec05c1e392eeb00"]}},"1acce1360fef474aa86b9abd11d6faab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cd501aa81f345d185b19a3f741e50d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ca515671c27c4905834982fd360c6649","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":685,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":685,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_368dd39a241b4903ae2a084be4697c7a"}},"500f8f5204db452f9ec05c1e392eeb00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d35c7207643f49dfa3b1f4fb6a81de81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 685/685 [00:40&lt;00:00, 16.86it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9f7fb247b0a41a0b25eef76e8337cd8"}},"ca515671c27c4905834982fd360c6649":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"368dd39a241b4903ae2a084be4697c7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d35c7207643f49dfa3b1f4fb6a81de81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f9f7fb247b0a41a0b25eef76e8337cd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"gxAkXurO4ed2"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"969WOYVB4sMG"},"source":["import csv\r\n","import os\r\n","import random\r\n","from pathlib import Path\r\n","import numpy as np\r\n","import pandas as pd\r\n","import torch\r\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\r\n","                              TensorDataset)\r\n","from torch.utils.data.distributed import DistributedSampler\r\n","from transformers import RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer\r\n","from transformers import AdamW, get_linear_schedule_with_warmup\r\n","from tqdm import tqdm, trange, tqdm_notebook\r\n","from sklearn.metrics import matthews_corrcoef, f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"Q1QTMaFx40y0","executionInfo":{"status":"ok","timestamp":1609351260576,"user_tz":-60,"elapsed":2756,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"89f9c425-4584-4117-a5ea-11c53e7ab63a"},"source":["dataset = pd.read_csv(\"data/preprocessed_train.csv\")\r\n","dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>id have responded if i were going</td>\n","      <td>id have responded if i were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>sooo sad i will miss you here in san diego</td>\n","      <td>sooo sad</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>sons of  why couldnt they put them on the rele...</td>\n","      <td>sons of</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27476</th>\n","      <td>4eac33d1c0</td>\n","      <td>wish we could come see u on denver husband los...</td>\n","      <td>d lost</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27477</th>\n","      <td>4f4c4fc327</td>\n","      <td>ive wondered about rake to the client has made...</td>\n","      <td>dont force</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27478</th>\n","      <td>f67aae2310</td>\n","      <td>yay good for both of you enjoy the break you p...</td>\n","      <td>yay good for both of you</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27479</th>\n","      <td>ed167662a5</td>\n","      <td>but it was worth it</td>\n","      <td>but it was worth it</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27480</th>\n","      <td>6f7127d9d7</td>\n","      <td>all this flirting going on the atg smiles yay ...</td>\n","      <td>all this flirting going on the atg smiles yay ...</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27481 rows × 4 columns</p>\n","</div>"],"text/plain":["           textID  ... sentiment\n","0      cb774db0d1  ...   neutral\n","1      549e992a42  ...  negative\n","2      088c60f138  ...  negative\n","3      9642c003ef  ...  negative\n","4      358bd9e861  ...  negative\n","...           ...  ...       ...\n","27476  4eac33d1c0  ...  negative\n","27477  4f4c4fc327  ...  negative\n","27478  f67aae2310  ...  positive\n","27479  ed167662a5  ...  positive\n","27480  6f7127d9d7  ...   neutral\n","\n","[27481 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"o8f8_Z0kz4iO"},"source":["dataset.dropna(inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"ZUrUmrmjz4k1","executionInfo":{"status":"ok","timestamp":1609351552294,"user_tz":-60,"elapsed":1327,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"05f304a9-8b0d-4a6d-a1d9-7e5f1954d3c9"},"source":["dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>id have responded if i were going</td>\n","      <td>id have responded if i were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>sooo sad i will miss you here in san diego</td>\n","      <td>sooo sad</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>sons of  why couldnt they put them on the rele...</td>\n","      <td>sons of</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27476</th>\n","      <td>4eac33d1c0</td>\n","      <td>wish we could come see u on denver husband los...</td>\n","      <td>d lost</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27477</th>\n","      <td>4f4c4fc327</td>\n","      <td>ive wondered about rake to the client has made...</td>\n","      <td>dont force</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27478</th>\n","      <td>f67aae2310</td>\n","      <td>yay good for both of you enjoy the break you p...</td>\n","      <td>yay good for both of you</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27479</th>\n","      <td>ed167662a5</td>\n","      <td>but it was worth it</td>\n","      <td>but it was worth it</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27480</th>\n","      <td>6f7127d9d7</td>\n","      <td>all this flirting going on the atg smiles yay ...</td>\n","      <td>all this flirting going on the atg smiles yay ...</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27383 rows × 4 columns</p>\n","</div>"],"text/plain":["           textID  ... sentiment\n","0      cb774db0d1  ...   neutral\n","1      549e992a42  ...  negative\n","2      088c60f138  ...  negative\n","3      9642c003ef  ...  negative\n","4      358bd9e861  ...  negative\n","...           ...  ...       ...\n","27476  4eac33d1c0  ...  negative\n","27477  4f4c4fc327  ...  negative\n","27478  f67aae2310  ...  positive\n","27479  ed167662a5  ...  positive\n","27480  6f7127d9d7  ...   neutral\n","\n","[27383 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"id":"dpwDnTHA48Vc","executionInfo":{"status":"ok","timestamp":1609351584653,"user_tz":-60,"elapsed":650,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"2c4a04fa-dc6e-41bb-9561-600cdec6ff08"},"source":["from sklearn.preprocessing import OrdinalEncoder\r\n","\r\n","ord_enc = OrdinalEncoder()\r\n","dataset[\"label\"] = ord_enc.fit_transform(dataset[[\"sentiment\"]])\r\n","dataset[[\"sentiment\", \"label\"]].head(11)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>positive</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>positive</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentiment  label\n","0    neutral    1.0\n","1   negative    0.0\n","2   negative    0.0\n","3   negative    0.0\n","4   negative    0.0\n","5    neutral    1.0\n","6   positive    2.0\n","7    neutral    1.0\n","8    neutral    1.0\n","9   positive    2.0\n","10   neutral    1.0"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"aki1pDzn50hg","executionInfo":{"status":"ok","timestamp":1609351588399,"user_tz":-60,"elapsed":826,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"0341f255-8c00-4abf-e14a-2cca6c47a15c"},"source":["dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>id have responded if i were going</td>\n","      <td>id have responded if i were going</td>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>sooo sad i will miss you here in san diego</td>\n","      <td>sooo sad</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>sons of  why couldnt they put them on the rele...</td>\n","      <td>sons of</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID  ... label\n","0  cb774db0d1  ...   1.0\n","1  549e992a42  ...   0.0\n","2  088c60f138  ...   0.0\n","3  9642c003ef  ...   0.0\n","4  358bd9e861  ...   0.0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TyOfPIu6EtO","executionInfo":{"status":"ok","timestamp":1609351590803,"user_tz":-60,"elapsed":1078,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"e29cdb51-b9c5-49f8-9aaa-bdacfc6858bf"},"source":["dataset.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(27383, 5)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"9swHoSGh_QlL"},"source":["#run this for case 1\r\n","dataset = dataset[['text','label']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aJkeeC_SWrr"},"source":["#run this for case 2\r\n","dataset = dataset[['selected_text','label']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"R_GWhFJ5_W4E","executionInfo":{"status":"ok","timestamp":1609351593576,"user_tz":-60,"elapsed":706,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"b52c05a0-a01d-48b7-b686-4677ecf6a98f"},"source":["dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id have responded if i were going</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sooo sad i will miss you here in san diego</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview leave me alone</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sons of  why couldnt they put them on the rele...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0                  id have responded if i were going    1.0\n","1         sooo sad i will miss you here in san diego    0.0\n","2                             my boss is bullying me    0.0\n","3                      what interview leave me alone    0.0\n","4  sons of  why couldnt they put them on the rele...    0.0"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CPo45-w54ez","executionInfo":{"status":"ok","timestamp":1609352321768,"user_tz":-60,"elapsed":1212,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"2950eeae-4f0b-49f5-f858-2ff548f30a8a"},"source":["#train and val split\r\n","\r\n","train_df = dataset.iloc[:19236]\r\n","vall_df = dataset.iloc[19236:]\r\n","train_df.shape, vall_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((19236, 2), (8147, 2))"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDlLFDsM38qS","executionInfo":{"status":"ok","timestamp":1609352336462,"user_tz":-60,"elapsed":1286,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"50042d0e-8947-4fa6-9597-9da6d2fb2ce8"},"source":["#val test split\r\n","\r\n","val_df = vall_df.iloc[:4122]\r\n","test_df = vall_df.iloc[4122:]\r\n","val_df.shape, test_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4122, 2), (4025, 2))"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"nBYKVQtm7qQx"},"source":["save_dir = \"data/\"\r\n","train_df.to_csv(save_dir + \"train.csv\", index=False)\r\n","val_df.to_csv(save_dir + \"dev.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Im_CMsfg7XML"},"source":["test_df.to_csv(save_dir + \"test.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGZz9CDp6Nmq"},"source":["class InputExample(object):\r\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\r\n","\r\n","    def __init__(self, guid, text_a, text_b=None, label=None):\r\n","        \"\"\"Constructs a InputExample.\r\n","        Args:\r\n","            guid: Unique id for the example.\r\n","            text_a: string. The untokenized text of the first sequence. For single\r\n","            sequence tasks, only this sequence must be specified.\r\n","            text_b: (Optional) string. The untokenized text of the second sequence.\r\n","            Only must be specified for sequence pair tasks.\r\n","            label: (Optional) string. The label of the example. This should be\r\n","            specified for train and dev examples, but not for test examples.\r\n","        \"\"\"\r\n","        self.guid = guid\r\n","        self.text_a = text_a\r\n","        self.text_b = text_b\r\n","        self.label = label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQvqkYnY6ZkZ"},"source":["class InputFeatures(object):\r\n","    \"\"\"A single set of features of data.\"\"\"\r\n","\r\n","    def __init__(self, input_ids, input_mask, segment_ids, label_id):\r\n","        self.input_ids = input_ids\r\n","        self.input_mask = input_mask\r\n","        self.segment_ids = segment_ids\r\n","        self.label_id = label_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KycuyRUt6d4w"},"source":["\r\n","class DataProcessor(object):\r\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\r\n","\r\n","    def get_train_examples(self, data_dir):\r\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","    def get_dev_examples(self, data_dir):\r\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","    def get_labels(self):\r\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","    @classmethod\r\n","    def _read_tsv(cls, input_file, quotechar=None):\r\n","        \"\"\"Reads a tab separated value file.\"\"\"\r\n","        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\r\n","            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\r\n","            lines = []\r\n","            for line in reader:\r\n","                if sys.version_info[0] == 2:\r\n","                    line = list(unicode(cell, 'utf-8') for cell in line)\r\n","                lines.append(line)\r\n","            return lines\r\n","          \r\n","class TweetProcessor(DataProcessor):\r\n","    \"\"\"Processor for the Amazon Reviews data set.\"\"\"\r\n","\r\n","    def get_train_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_tsv(os.path.join(data_dir, \"train.csv\")), \"train\")\r\n","\r\n","    def get_dev_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_tsv(os.path.join(data_dir, \"dev.csv\")), \"dev\")\r\n","\r\n","    def get_test_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_tsv(os.path.join(data_dir, \"test.csv\")), \"test\")\r\n","\r\n","    def get_labels(self):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return [0, 1, 2]\r\n","\r\n","    #Hack to be compatible with the existing code in transformers library\r\n","    def _read_tsv(self, file_path):\r\n","        return pd.read_csv(file_path).values.tolist()\r\n","\r\n","    def _create_examples(self, lines, set_type):\r\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\r\n","        examples = []\r\n","        for (i, line) in enumerate(lines):\r\n","            if i == 0:\r\n","               continue\r\n","            guid = \"%s-%s\" % (set_type, i)\r\n","            text_a = str(line[0])\r\n","           # text_b = None\r\n","            label = line[1]\r\n","            examples.append(\r\n","                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\r\n","        return examples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6uM9OJal6iF-"},"source":["def set_seed(seed):\r\n","    random.seed(seed)\r\n","    np.random.seed(seed)\r\n","    torch.manual_seed(seed)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVAmID3W6lVc"},"source":["def simple_accuracy(preds, labels):\r\n","  return (preds == labels).mean()\r\n","  \r\n","def acc_and_f1(preds, labels):\r\n","  acc = simple_accuracy(preds, labels)\r\n","  f1 = f1_score(y_true=labels, y_pred=preds)\r\n","  return {\r\n","      \"acc\": acc,\r\n","      \"f1\": f1,\r\n","     \r\n","  }\r\n","\r\n","\r\n","def f1_weighted(preds, labels):\r\n","  return f1_score(y_true=labels, y_pred=preds, average='weighted')\r\n","  \r\n","def compute_metrics(task_name, preds, labels):\r\n","  assert len(preds) == len(labels)\r\n","  if task_name == \"tweet\":\r\n","    return {\"acc\": acc_and_f1(preds, labels)}\r\n","  else:\r\n","    raise KeyError(task_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wk2MjBbu6npD"},"source":["def _truncate_seq_pair(tokens_a, tokens_b, max_length):\r\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\r\n","\r\n","    # This is a simple heuristic which will always truncate the longer sequence\r\n","    # one token at a time. This makes more sense than truncating an equal percent\r\n","    # of tokens from each, since if one sequence is very short then each token\r\n","    # that's truncated likely contains more information than a longer sequence.\r\n","    while True:\r\n","        total_length = len(tokens_a) + len(tokens_b)\r\n","        if total_length <= max_length:\r\n","            break\r\n","        if len(tokens_a) > len(tokens_b):\r\n","            tokens_a.pop()\r\n","        else:\r\n","            tokens_b.pop()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRP-i1VR6qoL"},"source":["def convert_examples_to_features(examples, label_list, max_seq_length,\r\n","                                 tokenizer, output_mode,\r\n","                                 cls_token_at_end=False, pad_on_left=False,\r\n","                                 cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\r\n","                                 sequence_a_segment_id=0, sequence_b_segment_id=1,\r\n","                                 cls_token_segment_id=1, pad_token_segment_id=0,\r\n","                                 mask_padding_with_zero=True):\r\n","    \"\"\" Loads a data file into a list of `InputBatch`s\r\n","        `cls_token_at_end` define the location of the CLS token:\r\n","            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\r\n","            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\r\n","        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\r\n","    \"\"\"\r\n","\r\n","    label_map = {label : i for i, label in enumerate(label_list)}\r\n","\r\n","    features = []\r\n","    for (ex_index, example) in enumerate(examples):\r\n","\r\n","        tokens_a = tokenizer.tokenize(example.text_a)\r\n","\r\n","        tokens_b = None\r\n","        if example.text_b:\r\n","            tokens_b = tokenizer.tokenize(example.text_b)\r\n","            # Modifies `tokens_a` and `tokens_b` in place so that the total\r\n","            # length is less than the specified length.\r\n","            # Account for [CLS], [SEP], [SEP] with \"- 3\"\r\n","            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\r\n","        else:\r\n","            # Account for [CLS] and [SEP] with \"- 2\"\r\n","            if len(tokens_a) > max_seq_length - 2:\r\n","                tokens_a = tokens_a[:(max_seq_length - 2)]\r\n","\r\n","        # The convention in BERT is:\r\n","        # (a) For sequence pairs:\r\n","        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\r\n","        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\r\n","        # (b) For single sequences:\r\n","        #  tokens:   [CLS] the dog is hairy . [SEP]\r\n","        #  type_ids:   0   0   0   0  0     0   0\r\n","        #\r\n","        # Where \"type_ids\" are used to indicate whether this is the first\r\n","        # sequence or the second sequence. The embedding vectors for `type=0` and\r\n","        # `type=1` were learned during pre-training and are added to the wordpiece\r\n","        # embedding vector (and position vector). This is not *strictly* necessary\r\n","        # since the [SEP] token unambiguously separates the sequences, but it makes\r\n","        # it easier for the model to learn the concept of sequences.\r\n","        #\r\n","        # For classification tasks, the first vector (corresponding to [CLS]) is\r\n","        # used as as the \"sentence vector\". Note that this only makes sense because\r\n","        # the entire model is fine-tuned.\r\n","        tokens = tokens_a + [sep_token]\r\n","        segment_ids = [sequence_a_segment_id] * len(tokens)\r\n","\r\n","        if tokens_b:\r\n","            tokens += tokens_b + [sep_token]\r\n","            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\r\n","\r\n","        if cls_token_at_end:\r\n","            tokens = tokens + [cls_token]\r\n","            segment_ids = segment_ids + [cls_token_segment_id]\r\n","        else:\r\n","            tokens = [cls_token] + tokens\r\n","            segment_ids = [cls_token_segment_id] + segment_ids\r\n","\r\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\r\n","\r\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real\r\n","        # tokens are attended to.\r\n","        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\r\n","\r\n","        # Zero-pad up to the sequence length.\r\n","        padding_length = max_seq_length - len(input_ids)\r\n","        if pad_on_left:\r\n","            input_ids = ([pad_token] * padding_length) + input_ids\r\n","            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\r\n","            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\r\n","        else:\r\n","            input_ids = input_ids + ([pad_token] * padding_length)\r\n","            input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\r\n","            segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\r\n","\r\n","        assert len(input_ids) == max_seq_length\r\n","        assert len(input_mask) == max_seq_length\r\n","        assert len(segment_ids) == max_seq_length\r\n","\r\n","        if output_mode == \"classification\":\r\n","            label_id = label_map[example.label]\r\n","        elif output_mode == \"regression\":\r\n","            label_id = float(example.label)\r\n","        else:\r\n","            raise KeyError(output_mode)\r\n","\r\n","        features.append(\r\n","                InputFeatures(input_ids=input_ids,\r\n","                              input_mask=input_mask,\r\n","                              segment_ids=segment_ids,\r\n","                              label_id=label_id))\r\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_bnAV7b60ZK"},"source":["\r\n","processor = TweetProcessor()\r\n","label_list = processor.get_labels()\r\n","num_labels = len(label_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z9RazYscD0bp","executionInfo":{"status":"ok","timestamp":1609352370003,"user_tz":-60,"elapsed":7293,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"a19b6ac9-4c89-4fd6-8834-1e4c9165ed0f"},"source":["#RobertaConfig, RobertaForSequenceClassification,RobertaTokenizer\r\n","config = RobertaConfig.from_pretrained('roberta-base', num_labels=num_labels)\r\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\r\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', config=config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9RFaKP0l8kRK"},"source":[" def load_and_cache_examples(tokenizer, dataset='train'):  \r\n","  if dataset == \"train\":\r\n","      examples = processor.get_train_examples(data_dir)\r\n","  elif dataset == \"dev\":\r\n","      examples = processor.get_dev_examples(data_dir)\r\n","  else:\r\n","      examples = processor.get_test_examples(data_dir)\r\n","  \r\n","  features = convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode,\r\n","            cls_token_at_end=True,            # xlnet has a cls token at the end\r\n","            cls_token=tokenizer.cls_token,\r\n","            sep_token=tokenizer.sep_token,\r\n","            cls_token_segment_id=2,\r\n","            pad_on_left=True,               # pad on the left for xlnet\r\n","            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\r\n","            pad_token_segment_id=4)\r\n","  # Convert to Tensors and build dataset\r\n","  all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\r\n","  all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\r\n","  all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\r\n","  if output_mode == \"classification\":\r\n","      all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\r\n","  elif output_mode == \"regression\":\r\n","      all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\r\n","\r\n","  dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\r\n","  return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vsiFZRF93rE","executionInfo":{"status":"ok","timestamp":1609352505148,"user_tz":-60,"elapsed":1246,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"67afe68f-3cec-459b-e23c-c5e93a642780"},"source":["output_mode = 'classification'\r\n","max_seq_length = 60\r\n","batch_size = 8\r\n","max_grad_norm = 1.0\r\n","gradient_accumulation_steps=2\r\n","num_train_epochs=3\r\n","weight_decay=0.0\r\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y4shGAUC-RfA"},"source":["learning_rate = 2e-5\r\n","adam_epsilon = 1e-8\r\n","num_warmup_steps = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGeQmWDw-bYN"},"source":["def train(train_dataset, model, tokenizer):\r\n","  \"\"\" Train the model \"\"\"\r\n","  train_sampler = RandomSampler(train_dataset)\r\n","  train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\r\n","  num_training_steps = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\r\n","  # Prepare optimizer and schedule (linear warmup and decay)\r\n","  no_decay = ['bias', 'LayerNorm.weight']\r\n","  optimizer_grouped_parameters = [\r\n","      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\r\n","      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\r\n","      ]\r\n","  optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\r\n","  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps= num_warmup_steps,num_training_steps = num_training_steps)\r\n","  \r\n","  global_step = 0\r\n","  tr_loss, logging_loss = 0.0, 0.0\r\n","  model.zero_grad()\r\n","  train_iterator = tqdm_notebook(range(int(num_train_epochs)), desc=\"Epoch\")\r\n","  set_seed(42)\r\n","  for _ in train_iterator:\r\n","    epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\r\n","    for step, batch in enumerate(epoch_iterator):\r\n","      model.train()\r\n","      batch = tuple(t.to(device) for t in batch)\r\n","      inputs = {'input_ids':      batch[0],\r\n","                'attention_mask': batch[1],\r\n","                'token_type_ids': None,       # XLM and RoBERTa don't use segment_ids\r\n","                'labels':         batch[3]}\r\n","      outputs = model(**inputs)\r\n","      loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\r\n","      if gradient_accumulation_steps > 1:\r\n","        loss = loss / gradient_accumulation_steps\r\n","      loss.backward()\r\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\r\n","      tr_loss += loss.item()\r\n","      if (step + 1) % gradient_accumulation_steps == 0:\r\n","          scheduler.step()  # Update learning rate schedule\r\n","          optimizer.step()\r\n","          model.zero_grad()\r\n","          global_step += 1\r\n","          \r\n","  return global_step, tr_loss / global_step"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dWLmYAJ-euq"},"source":["def evaluate(model, tokenizer, prefix=\"\"):\r\n","  results = {}\r\n","  eval_dataset = load_and_cache_examples(tokenizer, dataset='dev')\r\n","  eval_batch_size = 8\r\n","  eval_sampler = SequentialSampler(eval_dataset)\r\n","  eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\r\n","  eval_loss = 0.0\r\n","  nb_eval_steps = 0\r\n","  preds = None\r\n","  out_label_ids = None\r\n","  for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\r\n","    model.eval()\r\n","    batch = tuple(t.to(device) for t in batch)\r\n","    with torch.no_grad():\r\n","      inputs = {'input_ids':      batch[0],\r\n","                'attention_mask': batch[1],\r\n","                'token_type_ids': None,             # XLM and RoBERTa don't use segment_ids\r\n","                'labels':         batch[3]}\r\n","      outputs = model(**inputs)\r\n","      tmp_eval_loss, logits = outputs[:2]\r\n","      eval_loss += tmp_eval_loss.mean().item()\r\n","    \r\n","    nb_eval_steps += 1\r\n","    if preds is None:\r\n","        preds = logits.detach().cpu().numpy()\r\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\r\n","    else:\r\n","        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\r\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\r\n","  eval_loss = eval_loss / nb_eval_steps\r\n","  if output_mode == \"classification\":\r\n","      preds = np.argmax(preds, axis=1)\r\n","  elif output_mode == \"regression\":\r\n","      preds = np.squeeze(preds)\r\n","  result = compute_metrics(\"tweet\", preds, out_label_ids)\r\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335,"referenced_widgets":["aa165c4c8d4a4bdba30d669f59906d15","6ec0c4d438e34833979e9caa837ba5a7","14fd1204a16d4c3692e57e2852041c2b","6117124ef56747cb9660a3b0a1320814","18ac3a6a121c4a18910759f5c69e22f1","36db65bfa8214685b95ea2ea46b81bda","244e5d1e610e4e7180f83fa6e3ab8ab7","e803ea8467d848888de63596f4ee1920","dc452a3c7a0842309e44f5a32c1b82bd","e8412f4d3b8e46ab81d4f301157f00be","e8a92849a76642a7ab2b186ae0df4ae7","eaa7ef95bed7416aa97237bcff09b7af","853d9a7b580a474aafa0941123ff863b","4f78a0941ba24435b1ad3f9de377fcd7","3a2ae730cb3d470ab40b96c8e4e67058","ead4e7718c7a497bb0bc54fe8e19ae35","ca3c971fe77d454eaf3179146487dc44","82b8beb2e5284052846d9e1a554b65e2","cd664e45c6b24bc791ab4c063dd97b01","866d76086148468f8409464495f5b65e","a125e2c861bf40f88ec5448bb0ac14a4","aa163f956a7a48669f70ebbc50912fa9","aff54d05e66d4eddb83fec133c002263","305cb5e80a6943e6a714908a088c0398","c980297feeca4330a7ec8cd7b3611d63","738d1f6643bb4d0784fc279254b24134","43dd7167468747d9aac84ae9a003e42f","91a9349ed14b49cea0bd1d2762dfa7cf","3f1bbd86cedd44d79d5b9bbb1f502bd4","142219a840f3408d9b951aa884fa4362","b75ec03a81894ce6a13e232ad16222ab","638ece11c7014635a228491add1be51d"]},"id":"zlDfbUgj-mBF","executionInfo":{"status":"ok","timestamp":1609353103597,"user_tz":-60,"elapsed":588749,"user":{"displayName":"Rohith Teja","photoUrl":"https://lh3.googleusercontent.com/-nt8x4joQmgY/AAAAAAAAAAI/AAAAAAAAAvg/AbgIIUozOq0/s64/photo.jpg","userId":"01155222072916958278"}},"outputId":"1f17ff7a-4d66-4052-9113-34ec66e186cf"},"source":["data_dir= 'data'\r\n","model.to(device)\r\n","train_dataset = load_and_cache_examples(tokenizer, dataset=\"train\")\r\n","global_step, tr_loss = train(train_dataset, model, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aa165c4c8d4a4bdba30d669f59906d15","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc452a3c7a0842309e44f5a32c1b82bd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2405.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca3c971fe77d454eaf3179146487dc44","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2405.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c980297feeca4330a7ec8cd7b3611d63","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2405.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2nd7E7A8-sRW","colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["dfcc3e8bb29142aaaf0cf2a9d4ecce92","1acce1360fef474aa86b9abd11d6faab","1cd501aa81f345d185b19a3f741e50d4","500f8f5204db452f9ec05c1e392eeb00","ca515671c27c4905834982fd360c6649","368dd39a241b4903ae2a084be4697c7a","d35c7207643f49dfa3b1f4fb6a81de81","f9f7fb247b0a41a0b25eef76e8337cd8"]},"executionInfo":{"status":"ok","timestamp":1609278897437,"user_tz":-60,"elapsed":42042,"user":{"displayName":"Yogesh Kumar Pilli","photoUrl":"","userId":"08942912479073261381"}},"outputId":"5d9ede65-0392-41ff-be03-65514a54aa90"},"source":["# Evaluation\r\n","result = evaluate(model, tokenizer, prefix=global_step)\r\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfcc3e8bb29142aaaf0cf2a9d4ecce92","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=685.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","{'acc': 0.7791932919904274}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GIx38YdB_oHO"},"source":["def evaluatetest(model, tokenizer, prefix=\"\"):\r\n","  results = {}\r\n","  eval_dataset = load_and_cache_examples(tokenizer, dataset='test')\r\n","  eval_batch_size = 8\r\n","  eval_sampler = SequentialSampler(eval_dataset)\r\n","  eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\r\n","  eval_loss = 0.0\r\n","  nb_eval_steps = 0\r\n","  preds = None\r\n","  out_label_ids = None\r\n","  for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\r\n","    model.eval()\r\n","    batch = tuple(t.to(device) for t in batch)\r\n","    with torch.no_grad():\r\n","      inputs = {'input_ids':      batch[0],\r\n","                'attention_mask': batch[1],\r\n","                'token_type_ids': None,             # XLM and RoBERTa don't use segment_ids\r\n","                'labels':         batch[3]}\r\n","      outputs = model(**inputs)\r\n","      tmp_eval_loss, logits = outputs[:2]\r\n","      eval_loss += tmp_eval_loss.mean().item()\r\n","    \r\n","    nb_eval_steps += 1\r\n","    if preds is None:\r\n","        preds = logits.detach().cpu().numpy()\r\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\r\n","    else:\r\n","        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\r\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\r\n","  eval_loss = eval_loss / nb_eval_steps\r\n","  if output_mode == \"classification\":\r\n","      preds = np.argmax(preds, axis=1)\r\n","  elif output_mode == \"regression\":\r\n","      preds = np.squeeze(preds)\r\n","  result = compute_metrics(\"tweet\", preds, out_label_ids)\r\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uDyFnbBM4_gb"},"source":["# Evaluation\r\n","result = evaluatetest(model, tokenizer, prefix=global_step)\r\n","print(result)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EUIhxMbp4_jD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RwuIGFk4_ky"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6Tgzbr04_nQ"},"source":[""],"execution_count":null,"outputs":[]}]}