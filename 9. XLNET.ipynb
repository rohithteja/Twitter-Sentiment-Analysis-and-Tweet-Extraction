{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"9. XLNET.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"326675dcabd0449dbfda497d7c019cb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1edd8cc01947470ca0211879eec3e6b2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_763be4d7292a450e805a6114880bc78a","IPY_MODEL_03f6ef0d80084bf1a1f273287ae6178d"]}},"1edd8cc01947470ca0211879eec3e6b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"763be4d7292a450e805a6114880bc78a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_91540cac9fb34eccbffe8f69e27e014e","_dom_classes":[],"description":"Epoch: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53e5246d0c70495b85dcc68e74b87b3d"}},"03f6ef0d80084bf1a1f273287ae6178d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_21521da6e49d46618040740e4979f54d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [59:12&lt;00:00, 1184.25s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4e3846f7741c41f4925b668a3e5f6863"}},"91540cac9fb34eccbffe8f69e27e014e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"53e5246d0c70495b85dcc68e74b87b3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"21521da6e49d46618040740e4979f54d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4e3846f7741c41f4925b668a3e5f6863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a357cc9962724d438949e6b4b36e2b4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f7e408560d10481a9451995a5b4f8753","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cd3ef1c71a694cb2a417c7d2951ea7e5","IPY_MODEL_74287caf9ef041ab979848b954f5bdf6"]}},"f7e408560d10481a9451995a5b4f8753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd3ef1c71a694cb2a417c7d2951ea7e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_bc4adcf07cce4a3fbeff6812e1c45ad6","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2750,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2750,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e40595fd8f441fba2e45bd143b171c3"}},"74287caf9ef041ab979848b954f5bdf6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bafb1e06083648d5b6df1cbb2ea1ce52","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2750/2750 [59:12&lt;00:00,  1.29s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b0a7683e45e4fa2b6bbcaf9140afe9c"}},"bc4adcf07cce4a3fbeff6812e1c45ad6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5e40595fd8f441fba2e45bd143b171c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bafb1e06083648d5b6df1cbb2ea1ce52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4b0a7683e45e4fa2b6bbcaf9140afe9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"611c644197534af0adaa01af3330937d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_24f0d8fc18014105be52c46e05b378c2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_609f096410f248b69cb2bc2d6bedbacc","IPY_MODEL_5ab09b787f694fff9778fb1403080f77"]}},"24f0d8fc18014105be52c46e05b378c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"609f096410f248b69cb2bc2d6bedbacc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7c529ac773b54dbeb0ae3438485fd054","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2750,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2750,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6917ea7382644aa4a6eabeb83206a5b3"}},"5ab09b787f694fff9778fb1403080f77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f2924dee9a7f4bdeb6756f4eed196f02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2750/2750 [47:09&lt;00:00,  1.03s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_afb151e84a6743c8ac5993a809747721"}},"7c529ac773b54dbeb0ae3438485fd054":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6917ea7382644aa4a6eabeb83206a5b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f2924dee9a7f4bdeb6756f4eed196f02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"afb151e84a6743c8ac5993a809747721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b429a3d2b9f48e0a97adc7aabe5d258":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b3cfa8e6a0fd4c34a55e1829d8f30774","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4640f0000faa40839b176a44eb76e1f6","IPY_MODEL_cb66fd0f8578426990fef95eefe1002f"]}},"b3cfa8e6a0fd4c34a55e1829d8f30774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4640f0000faa40839b176a44eb76e1f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec6f54841d3e4af1847dab3dcb7c38e2","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2750,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2750,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_65a1b71f09cb433cb73563fda505fdfc"}},"cb66fd0f8578426990fef95eefe1002f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fcf72bcdf9fe42829480c5496fcf79dc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2750/2750 [35:07&lt;00:00,  1.30it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a751e4fa4f44715a5e982252029824e"}},"ec6f54841d3e4af1847dab3dcb7c38e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"65a1b71f09cb433cb73563fda505fdfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fcf72bcdf9fe42829480c5496fcf79dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a751e4fa4f44715a5e982252029824e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75b4f49dbf6c4bb78a5c2c142b2286b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2229e2b4e3094aa3882cbe2a1bdc59a9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_81abfbc62e2444fd838e2de06c8a126c","IPY_MODEL_bf7b67dd55dd4722a945a8fec6bbfa16"]}},"2229e2b4e3094aa3882cbe2a1bdc59a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81abfbc62e2444fd838e2de06c8a126c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_89e0f50baef6480ebce94e076c08cdd2","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":685,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":685,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_39caa3317c694551b69cc0eb737bc9fe"}},"bf7b67dd55dd4722a945a8fec6bbfa16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_56e2ff72344a4ece8042215110090126","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 685/685 [08:53&lt;00:00,  1.29it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e62e95ee70bd410a851773222347ac31"}},"89e0f50baef6480ebce94e076c08cdd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"39caa3317c694551b69cc0eb737bc9fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56e2ff72344a4ece8042215110090126":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e62e95ee70bd410a851773222347ac31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"807c1c5b99114680b49d40ce362fe8ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6daeafa087de42409f047b5f34610783","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_89f4ca51fe5d41b3b44301d699d52b4d","IPY_MODEL_0a409871ef794060895720cfbc539cf3"]}},"6daeafa087de42409f047b5f34610783":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89f4ca51fe5d41b3b44301d699d52b4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_420219f0420246bcb5521b18d86e9bf8","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":442,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":442,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33fbc4120dfa40ba86e764b16769ae36"}},"0a409871ef794060895720cfbc539cf3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4fbb2d66af18468da0cd695bf0a493e5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 442/442 [00:41&lt;00:00, 10.67it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e4904846b0f4f96ae8ef437b851d392"}},"420219f0420246bcb5521b18d86e9bf8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"33fbc4120dfa40ba86e764b16769ae36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4fbb2d66af18468da0cd695bf0a493e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7e4904846b0f4f96ae8ef437b851d392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"gxAkXurO4ed2"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"969WOYVB4sMG"},"source":["import csv\r\n","import os\r\n","import random\r\n","from pathlib import Path\r\n","import numpy as np\r\n","import pandas as pd\r\n","import torch\r\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\r\n","                              TensorDataset)\r\n","from torch.utils.data.distributed import DistributedSampler\r\n","from transformers import XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer\r\n","from transformers import AdamW, get_linear_schedule_with_warmup\r\n","from tqdm import tqdm, trange, tqdm_notebook\r\n","from sklearn.metrics import matthews_corrcoef, f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"Q1QTMaFx40y0","outputId":"335ad18d-e8d8-4ddc-d326-a21c6ee1ca04"},"source":["dataset = pd.read_csv('/content/drive/MyDrive/DeepLearningProject/train.csv')\r\n","dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID  ... sentiment\n","0  cb774db0d1  ...   neutral\n","1  549e992a42  ...  negative\n","2  088c60f138  ...  negative\n","3  9642c003ef  ...  negative\n","4  358bd9e861  ...  negative\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"dpwDnTHA48Vc","outputId":"7e8dffd9-59d5-476d-c57f-af5f207b77e9"},"source":["from sklearn.preprocessing import OrdinalEncoder\r\n","\r\n","ord_enc = OrdinalEncoder()\r\n","dataset[\"label\"] = ord_enc.fit_transform(dataset[[\"sentiment\"]])\r\n","dataset[[\"sentiment\", \"label\"]].head(11)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>positive</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>positive</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentiment  label\n","0    neutral    1.0\n","1   negative    0.0\n","2   negative    0.0\n","3   negative    0.0\n","4   negative    0.0\n","5    neutral    1.0\n","6   positive    2.0\n","7    neutral    1.0\n","8    neutral    1.0\n","9   positive    2.0\n","10   neutral    1.0"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"aki1pDzn50hg","outputId":"d1afd568-4414-4bbe-effb-2bb68415d760"},"source":["dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID  ... label\n","0  cb774db0d1  ...   1.0\n","1  549e992a42  ...   0.0\n","2  088c60f138  ...   0.0\n","3  9642c003ef  ...   0.0\n","4  358bd9e861  ...   0.0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TyOfPIu6EtO","outputId":"b23004e1-0efd-495b-944d-0a78828ead4d"},"source":["dataset.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(27481, 5)"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"9swHoSGh_QlL"},"source":["#run this for case 1\r\n","dataset = dataset[['text','label']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TR4WWKE0SfVi"},"source":["#run this for case 2\r\n","dataset = dataset[['selected_text','label']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"R_GWhFJ5_W4E","outputId":"28d36cc7-1dfc-4b40-f5d1-75154cddd94b"},"source":["dataset.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0                I`d have responded, if I were going    1.0\n","1      Sooo SAD I will miss you here in San Diego!!!    0.0\n","2                          my boss is bullying me...    0.0\n","3                     what interview! leave me alone    0.0\n","4   Sons of ****, why couldn`t they put them on t...    0.0"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"RhYIEuaBJ6dh"},"source":["datatest = pd.read_csv(\"/content/drive/MyDrive/DeepLearningProject/test.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"B2b2OTCdKAIH","outputId":"6f642c99-ee30-4c6b-a002-bb7f2aff7069"},"source":["datatest.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>f87dea47db</td>\n","      <td>Last session of the day  http://twitpic.com/67ezh</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>96d74cb729</td>\n","      <td>Shanghai is also really exciting (precisely -...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>eee518ae67</td>\n","      <td>Recession hit Veronique Branquinho, she has to...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01082688c6</td>\n","      <td>happy bday!</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33987a8ee5</td>\n","      <td>http://twitpic.com/4w75p - I like it!!</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID                                               text sentiment\n","0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n","1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n","2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n","3  01082688c6                                        happy bday!  positive\n","4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"]},"metadata":{"tags":[]},"execution_count":80}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"id":"W1fSU8TVKVls","outputId":"ed4f476e-9cc0-419f-b675-23ca888d2d44"},"source":["from sklearn.preprocessing import OrdinalEncoder\r\n","\r\n","ord_enc = OrdinalEncoder()\r\n","datatest[\"label\"] = ord_enc.fit_transform(datatest[[\"sentiment\"]])\r\n","datatest[[\"sentiment\", \"label\"]].head(3)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>neutral</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>positive</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>negative</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  sentiment  label\n","0   neutral    1.0\n","1  positive    2.0\n","2  negative    0.0"]},"metadata":{"tags":[]},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"sK0zY5MDKDwN"},"source":["datatest = datatest[['text','label']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"SBxUxi0VKum2","outputId":"abdd04d5-3bc4-4c11-f056-9f8a54789456"},"source":["datatest"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Last session of the day  http://twitpic.com/67ezh</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Shanghai is also really exciting (precisely -...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Recession hit Veronique Branquinho, she has to...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>happy bday!</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>http://twitpic.com/4w75p - I like it!!</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3529</th>\n","      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3530</th>\n","      <td>All alone in this old house again.  Thanks for...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3531</th>\n","      <td>I know what you mean. My little dog is sinkin...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3532</th>\n","      <td>_sutra what is your next youtube video gonna b...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3533</th>\n","      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3534 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   text  label\n","0     Last session of the day  http://twitpic.com/67ezh    1.0\n","1      Shanghai is also really exciting (precisely -...    2.0\n","2     Recession hit Veronique Branquinho, she has to...    0.0\n","3                                           happy bday!    2.0\n","4                http://twitpic.com/4w75p - I like it!!    2.0\n","...                                                 ...    ...\n","3529  its at 3 am, im very tired but i can`t sleep  ...    0.0\n","3530  All alone in this old house again.  Thanks for...    2.0\n","3531   I know what you mean. My little dog is sinkin...    0.0\n","3532  _sutra what is your next youtube video gonna b...    2.0\n","3533   http://twitpic.com/4woj2 - omgssh  ang cute n...    2.0\n","\n","[3534 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CPo45-w54ez","outputId":"1691b7c6-5cc1-4e48-a050-509f2e450c26"},"source":["train_df = dataset.iloc[:22000]\r\n","val_df = dataset.iloc[22000:]\r\n","\r\n","train_df.shape, val_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((22000, 2), (5481, 2))"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"nBYKVQtm7qQx"},"source":["save_dir = Path('/content/drive/MyDrive/DeepLearningProject/TweetSentimentAnalysis/')\r\n","train_df.to_csv(str(save_dir / \"train.csv\"), index=False)\r\n","val_df.to_csv(str(save_dir / \"dev.csv\"), index=False)\r\n","datatest.to_csv(str(save_dir / \"test.csv\"),index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGZz9CDp6Nmq"},"source":["class InputExample(object):\r\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\r\n","\r\n","    def __init__(self, guid, text_a, text_b=None, label=None):\r\n","        \"\"\"Constructs a InputExample.\r\n","        Args:\r\n","            guid: Unique id for the example.\r\n","            text_a: string. The untokenized text of the first sequence. For single\r\n","            sequence tasks, only this sequence must be specified.\r\n","            text_b: (Optional) string. The untokenized text of the second sequence.\r\n","            Only must be specified for sequence pair tasks.\r\n","            label: (Optional) string. The label of the example. This should be\r\n","            specified for train and dev examples, but not for test examples.\r\n","        \"\"\"\r\n","        self.guid = guid\r\n","        self.text_a = text_a\r\n","        self.text_b = text_b\r\n","        self.label = label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQvqkYnY6ZkZ"},"source":["class InputFeatures(object):\r\n","    \"\"\"A single set of features of data.\"\"\"\r\n","\r\n","    def __init__(self, input_ids, input_mask, segment_ids, label_id):\r\n","        self.input_ids = input_ids\r\n","        self.input_mask = input_mask\r\n","        self.segment_ids = segment_ids\r\n","        self.label_id = label_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KycuyRUt6d4w"},"source":["\r\n","class DataProcessor(object):\r\n","    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\r\n","\r\n","    def get_train_examples(self, data_dir):\r\n","        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","    def get_dev_examples(self, data_dir):\r\n","        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","    def get_labels(self):\r\n","        \"\"\"Gets the list of labels for this data set.\"\"\"\r\n","        raise NotImplementedError()\r\n","\r\n","    @classmethod\r\n","    def _read_tsv(cls, input_file, quotechar=None):\r\n","        \"\"\"Reads a tab separated value file.\"\"\"\r\n","        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\r\n","            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\r\n","            lines = []\r\n","            for line in reader:\r\n","                if sys.version_info[0] == 2:\r\n","                    line = list(unicode(cell, 'utf-8') for cell in line)\r\n","                lines.append(line)\r\n","            return lines\r\n","          \r\n","class TweetProcessor(DataProcessor):\r\n","    \"\"\"Processor for the Amazon Reviews data set.\"\"\"\r\n","\r\n","    def get_train_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_tsv(os.path.join(data_dir, \"train.csv\")), \"train\")\r\n","\r\n","    def get_dev_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_tsv(os.path.join(data_dir, \"dev.csv\")), \"dev\")\r\n","\r\n","    def get_test_examples(self, data_dir):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return self._create_examples(\r\n","            self._read_tsv(os.path.join(data_dir, \"test.csv\")), \"test\")\r\n","\r\n","    def get_labels(self):\r\n","        \"\"\"See base class.\"\"\"\r\n","        return [0, 1, 2]\r\n","\r\n","    #Hack to be compatible with the existing code in transformers library\r\n","    def _read_tsv(self, file_path):\r\n","        return pd.read_csv(file_path).values.tolist()\r\n","\r\n","    def _create_examples(self, lines, set_type):\r\n","        \"\"\"Creates examples for the training and dev sets.\"\"\"\r\n","        examples = []\r\n","        for (i, line) in enumerate(lines):\r\n","            if i == 0:\r\n","               continue\r\n","            guid = \"%s-%s\" % (set_type, i)\r\n","            text_a = str(line[0])\r\n","           # text_b = None\r\n","            label = line[1]\r\n","            examples.append(\r\n","                InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\r\n","        return examples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6uM9OJal6iF-"},"source":["def set_seed(seed):\r\n","    random.seed(seed)\r\n","    np.random.seed(seed)\r\n","    torch.manual_seed(seed)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVAmID3W6lVc"},"source":["def simple_accuracy(preds, labels):\r\n","  return (preds == labels).mean()\r\n","  \r\n","def acc_and_f1(preds, labels):\r\n","  acc = simple_accuracy(preds, labels)\r\n","  f1 = f1_score(y_true=labels, y_pred=preds)\r\n","  return {\r\n","      \"acc\": acc,\r\n","      \"f1\": f1,\r\n","      \"acc_and_f1\": (acc + f1) / 2,\r\n","  }\r\n","\r\n","\r\n","def f1_weighted(preds, labels):\r\n","  return f1_score(y_true=labels, y_pred=preds, average='weighted')\r\n","  \r\n","def compute_metrics(task_name, preds, labels):\r\n","  assert len(preds) == len(labels)\r\n","  if task_name == \"tweet\":\r\n","    return {\"acc\": f1_weighted(preds, labels)}\r\n","  else:\r\n","    raise KeyError(task_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wk2MjBbu6npD"},"source":["def _truncate_seq_pair(tokens_a, tokens_b, max_length):\r\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\r\n","\r\n","    # This is a simple heuristic which will always truncate the longer sequence\r\n","    # one token at a time. This makes more sense than truncating an equal percent\r\n","    # of tokens from each, since if one sequence is very short then each token\r\n","    # that's truncated likely contains more information than a longer sequence.\r\n","    while True:\r\n","        total_length = len(tokens_a) + len(tokens_b)\r\n","        if total_length <= max_length:\r\n","            break\r\n","        if len(tokens_a) > len(tokens_b):\r\n","            tokens_a.pop()\r\n","        else:\r\n","            tokens_b.pop()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRP-i1VR6qoL"},"source":["def convert_examples_to_features(examples, label_list, max_seq_length,\r\n","                                 tokenizer, output_mode,\r\n","                                 cls_token_at_end=False, pad_on_left=False,\r\n","                                 cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\r\n","                                 sequence_a_segment_id=0, sequence_b_segment_id=1,\r\n","                                 cls_token_segment_id=1, pad_token_segment_id=0,\r\n","                                 mask_padding_with_zero=True):\r\n","    \"\"\" Loads a data file into a list of `InputBatch`s\r\n","        `cls_token_at_end` define the location of the CLS token:\r\n","            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\r\n","            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\r\n","        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\r\n","    \"\"\"\r\n","\r\n","    label_map = {label : i for i, label in enumerate(label_list)}\r\n","\r\n","    features = []\r\n","    for (ex_index, example) in enumerate(examples):\r\n","\r\n","        tokens_a = tokenizer.tokenize(example.text_a)\r\n","\r\n","        tokens_b = None\r\n","        if example.text_b:\r\n","            tokens_b = tokenizer.tokenize(example.text_b)\r\n","            # Modifies `tokens_a` and `tokens_b` in place so that the total\r\n","            # length is less than the specified length.\r\n","            # Account for [CLS], [SEP], [SEP] with \"- 3\"\r\n","            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\r\n","        else:\r\n","            # Account for [CLS] and [SEP] with \"- 2\"\r\n","            if len(tokens_a) > max_seq_length - 2:\r\n","                tokens_a = tokens_a[:(max_seq_length - 2)]\r\n","\r\n","        # The convention in BERT is:\r\n","        # (a) For sequence pairs:\r\n","        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\r\n","        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\r\n","        # (b) For single sequences:\r\n","        #  tokens:   [CLS] the dog is hairy . [SEP]\r\n","        #  type_ids:   0   0   0   0  0     0   0\r\n","        #\r\n","        # Where \"type_ids\" are used to indicate whether this is the first\r\n","        # sequence or the second sequence. The embedding vectors for `type=0` and\r\n","        # `type=1` were learned during pre-training and are added to the wordpiece\r\n","        # embedding vector (and position vector). This is not *strictly* necessary\r\n","        # since the [SEP] token unambiguously separates the sequences, but it makes\r\n","        # it easier for the model to learn the concept of sequences.\r\n","        #\r\n","        # For classification tasks, the first vector (corresponding to [CLS]) is\r\n","        # used as as the \"sentence vector\". Note that this only makes sense because\r\n","        # the entire model is fine-tuned.\r\n","        tokens = tokens_a + [sep_token]\r\n","        segment_ids = [sequence_a_segment_id] * len(tokens)\r\n","\r\n","        if tokens_b:\r\n","            tokens += tokens_b + [sep_token]\r\n","            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\r\n","\r\n","        if cls_token_at_end:\r\n","            tokens = tokens + [cls_token]\r\n","            segment_ids = segment_ids + [cls_token_segment_id]\r\n","        else:\r\n","            tokens = [cls_token] + tokens\r\n","            segment_ids = [cls_token_segment_id] + segment_ids\r\n","\r\n","        input_ids = tokenizer.convert_tokens_to_ids(tokens)\r\n","\r\n","        # The mask has 1 for real tokens and 0 for padding tokens. Only real\r\n","        # tokens are attended to.\r\n","        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\r\n","\r\n","        # Zero-pad up to the sequence length.\r\n","        padding_length = max_seq_length - len(input_ids)\r\n","        if pad_on_left:\r\n","            input_ids = ([pad_token] * padding_length) + input_ids\r\n","            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\r\n","            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\r\n","        else:\r\n","            input_ids = input_ids + ([pad_token] * padding_length)\r\n","            input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\r\n","            segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\r\n","\r\n","        assert len(input_ids) == max_seq_length\r\n","        assert len(input_mask) == max_seq_length\r\n","        assert len(segment_ids) == max_seq_length\r\n","\r\n","        if output_mode == \"classification\":\r\n","            label_id = label_map[example.label]\r\n","        elif output_mode == \"regression\":\r\n","            label_id = float(example.label)\r\n","        else:\r\n","            raise KeyError(output_mode)\r\n","\r\n","        features.append(\r\n","                InputFeatures(input_ids=input_ids,\r\n","                              input_mask=input_mask,\r\n","                              segment_ids=segment_ids,\r\n","                              label_id=label_id))\r\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_bnAV7b60ZK"},"source":["\r\n","processor = TweetProcessor()\r\n","label_list = processor.get_labels()\r\n","num_labels = len(label_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZQnASgo8ecf","outputId":"0efeac37-8cc7-47d4-f2b8-f599fa1ff86f"},"source":["#XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer\r\n","config = XLNetConfig.from_pretrained('xlnet-base-cased', num_labels=num_labels)\r\n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False)\r\n","model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', config=config)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9RFaKP0l8kRK"},"source":[" def load_and_cache_examples(tokenizer, dataset='train'):  \r\n","  if dataset == \"train\":\r\n","      examples = processor.get_train_examples(data_dir)\r\n","  elif dataset == \"dev\":\r\n","      examples = processor.get_dev_examples(data_dir)\r\n","  else:\r\n","      examples = processor.get_test_examples(data_dir)\r\n","  \r\n","  features = convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, output_mode,\r\n","            cls_token_at_end=True,            # xlnet has a cls token at the end\r\n","            cls_token=tokenizer.cls_token,\r\n","            sep_token=tokenizer.sep_token,\r\n","            cls_token_segment_id=2,\r\n","            pad_on_left=True,               # pad on the left for xlnet\r\n","            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\r\n","            pad_token_segment_id=4)\r\n","  # Convert to Tensors and build dataset\r\n","  all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\r\n","  all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\r\n","  all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\r\n","  if output_mode == \"classification\":\r\n","      all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\r\n","  elif output_mode == \"regression\":\r\n","      all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\r\n","\r\n","  dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\r\n","  return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vsiFZRF93rE","outputId":"36cb1f5d-fa37-498b-9654-d27a5054d03b"},"source":["output_mode = 'classification'\r\n","max_seq_length = 128\r\n","batch_size = 8\r\n","max_grad_norm = 1.0\r\n","gradient_accumulation_steps=2\r\n","num_train_epochs=3\r\n","weight_decay=0.0\r\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y4shGAUC-RfA"},"source":["learning_rate = 2e-5\r\n","adam_epsilon = 1e-8\r\n","warmup_steps = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGeQmWDw-bYN"},"source":["def train(train_dataset, model, tokenizer):\r\n","  \"\"\" Train the model \"\"\"\r\n","  train_sampler = RandomSampler(train_dataset)\r\n","  train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\r\n","  t_total = len(train_dataloader) // gradient_accumulation_steps * num_train_epochs\r\n","  # Prepare optimizer and schedule (linear warmup and decay)\r\n","  no_decay = ['bias', 'LayerNorm.weight']\r\n","  optimizer_grouped_parameters = [\r\n","      {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\r\n","      {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\r\n","      ]\r\n","  optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\r\n","  scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_steps, t_total=t_total)\r\n","  \r\n","  global_step = 0\r\n","  tr_loss, logging_loss = 0.0, 0.0\r\n","  model.zero_grad()\r\n","  train_iterator = tqdm_notebook(range(int(num_train_epochs)), desc=\"Epoch\")\r\n","  set_seed(42)\r\n","  for _ in train_iterator:\r\n","    epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\r\n","    for step, batch in enumerate(epoch_iterator):\r\n","      model.train()\r\n","      batch = tuple(t.to(device) for t in batch)\r\n","      inputs = {'input_ids':      batch[0],\r\n","                'attention_mask': batch[1],\r\n","                'token_type_ids': batch[2],\r\n","                'labels':         batch[3]}\r\n","      outputs = model(**inputs)\r\n","      loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\r\n","      if gradient_accumulation_steps > 1:\r\n","        loss = loss / gradient_accumulation_steps\r\n","      loss.backward()\r\n","      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\r\n","      tr_loss += loss.item()\r\n","      if (step + 1) % gradient_accumulation_steps == 0:\r\n","          scheduler.step()  # Update learning rate schedule\r\n","          optimizer.step()\r\n","          model.zero_grad()\r\n","          global_step += 1\r\n","          \r\n","  return global_step, tr_loss / global_step"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dWLmYAJ-euq"},"source":["def evaluate(model, tokenizer, prefix=\"\"):\r\n","  results = {}\r\n","  eval_dataset = load_and_cache_examples(tokenizer, dataset='dev')\r\n","  eval_batch_size = 8\r\n","  eval_sampler = SequentialSampler(eval_dataset)\r\n","  eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\r\n","  eval_loss = 0.0\r\n","  nb_eval_steps = 0\r\n","  preds = None\r\n","  out_label_ids = None\r\n","  for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\r\n","    model.eval()\r\n","    batch = tuple(t.to(device) for t in batch)\r\n","    with torch.no_grad():\r\n","      inputs = {'input_ids':      batch[0],\r\n","                'attention_mask': batch[1],\r\n","                'token_type_ids': batch[2],  # XLM don't use segment_ids\r\n","                'labels':         batch[3]}\r\n","      outputs = model(**inputs)\r\n","      tmp_eval_loss, logits = outputs[:2]\r\n","      eval_loss += tmp_eval_loss.mean().item()\r\n","    \r\n","    nb_eval_steps += 1\r\n","    if preds is None:\r\n","        preds = logits.detach().cpu().numpy()\r\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\r\n","    else:\r\n","        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\r\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\r\n","  eval_loss = eval_loss / nb_eval_steps\r\n","  if output_mode == \"classification\":\r\n","      preds = np.argmax(preds, axis=1)\r\n","  elif output_mode == \"regression\":\r\n","      preds = np.squeeze(preds)\r\n","  result = compute_metrics(\"tweet\", preds, out_label_ids)\r\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333,"referenced_widgets":["326675dcabd0449dbfda497d7c019cb1","1edd8cc01947470ca0211879eec3e6b2","763be4d7292a450e805a6114880bc78a","03f6ef0d80084bf1a1f273287ae6178d","91540cac9fb34eccbffe8f69e27e014e","53e5246d0c70495b85dcc68e74b87b3d","21521da6e49d46618040740e4979f54d","4e3846f7741c41f4925b668a3e5f6863","a357cc9962724d438949e6b4b36e2b4d","f7e408560d10481a9451995a5b4f8753","cd3ef1c71a694cb2a417c7d2951ea7e5","74287caf9ef041ab979848b954f5bdf6","bc4adcf07cce4a3fbeff6812e1c45ad6","5e40595fd8f441fba2e45bd143b171c3","bafb1e06083648d5b6df1cbb2ea1ce52","4b0a7683e45e4fa2b6bbcaf9140afe9c","611c644197534af0adaa01af3330937d","24f0d8fc18014105be52c46e05b378c2","609f096410f248b69cb2bc2d6bedbacc","5ab09b787f694fff9778fb1403080f77","7c529ac773b54dbeb0ae3438485fd054","6917ea7382644aa4a6eabeb83206a5b3","f2924dee9a7f4bdeb6756f4eed196f02","afb151e84a6743c8ac5993a809747721","7b429a3d2b9f48e0a97adc7aabe5d258","b3cfa8e6a0fd4c34a55e1829d8f30774","4640f0000faa40839b176a44eb76e1f6","cb66fd0f8578426990fef95eefe1002f","ec6f54841d3e4af1847dab3dcb7c38e2","65a1b71f09cb433cb73563fda505fdfc","fcf72bcdf9fe42829480c5496fcf79dc","4a751e4fa4f44715a5e982252029824e"]},"id":"zlDfbUgj-mBF","outputId":"dde02ac3-bd6e-4cc3-f732-95ed5e793e6d"},"source":["data_dir= '/content/drive/MyDrive/DeepLearningProject/TweetSentimentAnalysis/'\r\n","model.to(device)\r\n","train_dataset = load_and_cache_examples(tokenizer, dataset=\"train\")\r\n","global_step, tr_loss = train(train_dataset, model, tokenizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"326675dcabd0449dbfda497d7c019cb1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a357cc9962724d438949e6b4b36e2b4d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2750.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"611c644197534af0adaa01af3330937d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2750.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b429a3d2b9f48e0a97adc7aabe5d258","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2750.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133,"referenced_widgets":["75b4f49dbf6c4bb78a5c2c142b2286b9","2229e2b4e3094aa3882cbe2a1bdc59a9","81abfbc62e2444fd838e2de06c8a126c","bf7b67dd55dd4722a945a8fec6bbfa16","89e0f50baef6480ebce94e076c08cdd2","39caa3317c694551b69cc0eb737bc9fe","56e2ff72344a4ece8042215110090126","e62e95ee70bd410a851773222347ac31"]},"id":"2nd7E7A8-sRW","outputId":"8ed5f155-177d-4518-9206-fb4703c4bf1e"},"source":["# Evaluation\r\n","result = evaluate(model, tokenizer, prefix=global_step)\r\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75b4f49dbf6c4bb78a5c2c142b2286b9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=685.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","{'acc': 0.7823357350482024}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GIx38YdB_oHO"},"source":["def evaluatetest(model, tokenizer, prefix=\"\"):\r\n","  results = {}\r\n","  eval_dataset = load_and_cache_examples(tokenizer, dataset='test')\r\n","  eval_batch_size = 8\r\n","  eval_sampler = SequentialSampler(eval_dataset)\r\n","  eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=eval_batch_size)\r\n","  eval_loss = 0.0\r\n","  nb_eval_steps = 0\r\n","  preds = None\r\n","  out_label_ids = None\r\n","  for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\r\n","    model.eval()\r\n","    batch = tuple(t.to(device) for t in batch)\r\n","    with torch.no_grad():\r\n","      inputs = {'input_ids':      batch[0],\r\n","                'attention_mask': batch[1],\r\n","                'token_type_ids': batch[2],  # XLM don't use segment_ids\r\n","                'labels':         batch[3]}\r\n","      outputs = model(**inputs)\r\n","      tmp_eval_loss, logits = outputs[:2]\r\n","      eval_loss += tmp_eval_loss.mean().item()\r\n","    \r\n","    nb_eval_steps += 1\r\n","    if preds is None:\r\n","        preds = logits.detach().cpu().numpy()\r\n","        out_label_ids = inputs['labels'].detach().cpu().numpy()\r\n","    else:\r\n","        preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\r\n","        out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\r\n","  eval_loss = eval_loss / nb_eval_steps\r\n","  if output_mode == \"classification\":\r\n","      preds = np.argmax(preds, axis=1)\r\n","  elif output_mode == \"regression\":\r\n","      preds = np.squeeze(preds)\r\n","  result = compute_metrics(\"tweet\", preds, out_label_ids)\r\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133,"referenced_widgets":["807c1c5b99114680b49d40ce362fe8ac","6daeafa087de42409f047b5f34610783","89f4ca51fe5d41b3b44301d699d52b4d","0a409871ef794060895720cfbc539cf3","420219f0420246bcb5521b18d86e9bf8","33fbc4120dfa40ba86e764b16769ae36","4fbb2d66af18468da0cd695bf0a493e5","7e4904846b0f4f96ae8ef437b851d392"]},"id":"UpNwMaEUJoPh","outputId":"07c17ba5-084c-4751-be52-c573c109963f"},"source":["# Evaluation\r\n","result = evaluatetest(model, tokenizer, prefix=global_step)\r\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"807c1c5b99114680b49d40ce362fe8ac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=442.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","{'acc': 0.7877780857541329}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hBJYdu02NM7Y"},"source":[""],"execution_count":null,"outputs":[]}]}